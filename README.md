# ğŸµ SoundSteps: Digital Hearing Rehabilitation Platform

> **âš ï¸ AI AGENT INSTRUCTIONS:** Before writing code, you MUST read `docs/CONTRIBUTING.md`.

## ğŸ“ Development Standards
This project follows strict development and design standards to ensure consistency and prevent regressions.

### Required Reading
- ğŸ“˜ [Style Guide](docs/STYLE_GUIDE.md) - UI/UX standards and component patterns
- ğŸ› ï¸ [Contributing Guide](docs/CONTRIBUTING.md) - Engineering protocols and safety standards

---

**SoundSteps** is a scientifically-backed, gamified auditory training application designed for **Cochlear Implant (CI) recipients** and individuals with hearing loss. It focuses on the hierarchy of auditory skills: Detection, Discrimination, Identification, and Comprehension.

## ğŸš€ Project Status: React Migration (Phase 5 Complete)

We have successfully migrated the prototype from legacy vanilla JS to a modern **React + TypeScript + Vite** architecture.

### Key Features
*   **ğŸ§ Robust Audio Engine:** Custom `useAudio` hook with loading states, error handling, and progress tracking.
*   **ğŸšï¸ SNR Mixer (Speech-in-Noise):** "Pro" feature allowing users to adjust the balance between voice and background noise (e.g., Cafe, Traffic) to train listening in difficult environments.
*   **ğŸ—£ï¸ 4-Voice System:** Switch globally between David, Marcus (Male) and Sarah, Emma (Female) to train pitch perception.
*   **âš¡ Rapid Fire (Minimal Pairs):** High-repetition discrimination training (e.g., "Pear" vs. "Bear") using **ElevenLabs Turbo v2.5**.
*   **ğŸ“– Interactive Stories:** Narrative comprehension with adaptive audio.

## ğŸ› ï¸ Tech Stack

*   **Frontend:** React 18, TypeScript, Vite
*   **Styling:** Tailwind CSS (v3), Lucide React (Icons)
*   **State Management:** React Context (`VoiceContext`)
*   **Routing:** React Router v6
*   **Audio:** Native HTML5 Audio API with custom hooks
*   **Assets:** ElevenLabs generated audio (stored in `public/hearing-rehab-audio`)

## ğŸ“‚ Project Structure

```
my-hearing-app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/     # Reusable UI (AudioPlayer, QuizCard, SNRMixer)
â”‚   â”œâ”€â”€ hooks/          # Logic (useAudio, useAudioMixer)
â”‚   â”œâ”€â”€ pages/          # Screens (Dashboard, Player, RapidFire, AudioQA)
â”‚   â”œâ”€â”€ data/           # Static content (stories.ts, scenarios.ts, minimalPairs.ts)
â”‚   â”œâ”€â”€ store/          # Global state (VoiceContext)
â”‚   â””â”€â”€ types/          # TypeScript interfaces
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ hearing-rehab-audio/  # Voice assets (David, Sarah, etc.)
â”‚   â”œâ”€â”€ noise_files/          # Background noise tracks
â”‚   â””â”€â”€ audio_quality_test/   # QA samples
â”œâ”€â”€ legacy/             # Old vanilla JS prototype (Archived)
â””â”€â”€ generate_minimal_pairs.py # Script for generating new assets
```

## âš¡ Quick Start

1.  **Install Dependencies:**
    ```bash
    npm install
    ```

2.  **Run Local Development Server:**
    ```bash
    npm run dev
    ```
    Open `http://localhost:5173` in your browser.

3.  **Generate Audio Assets (Optional):**
    If you need to generate new Minimal Pairs, ensure your `.env` has a valid `ELEVENLABS_API_KEY` and run:
    ```bash
    python3 generate_minimal_pairs.py
    ```

## ğŸ—ºï¸ Roadmap & Progress

| Phase | Objective | Status | Notes |
|-------|-----------|--------|-------|
| **1** | **Structural Pivot** | âœ… Done | Migrated to React/Vite. |
| **1.5**| **Navigation** | âœ… Done | Implemented Router & Layout. |
| **2** | **Audio Engine** | âœ… Done | Built `useAudio` & `SNRMixer`. |
| **3** | **Active Learning** | âœ… Done | Built `QuizCard` & Feedback loop. |
| **4** | **Data Layer** | âœ… Done | Migrated CSVs to TypeScript data modules. |
| **5** | **Personalization** | âœ… Done | Global Voice Settings implemented. |
| **6** | **Asset Pipeline** | âœ… Done | Script `generate_minimal_pairs.py` creates assets for all 4 voices using Turbo v2.5. |
| **7** | **Visual Polish** | ğŸ“… Next | Add animations, improved typography, and "Audiogram" visualizations. |
| **8** | **Advanced Audio** | ğŸ”® Future | **ElevenLabs Features:**<br>â€¢ **Karaoke Mode:** Real-time word highlighting via *Forced Alignment API*.<br>â€¢ **Dynamic Ambience:** Generative backgrounds via *Sound Effects API*.<br>â€¢ **Voice Lab:** Custom voice design for pitch training ladders. |
| **9** | **Conversational AI** | ğŸ”® Future | **Agent Integration (Scribe v2):**<br>â€¢ **"The Barista Bot":** Live roleplay (ordering coffee).<br>â€¢ **"Telephone Mode":** Audio-only conversation practice. |

## ğŸ“š ElevenLabs Reference Links
*   [Text to Speech Capabilities](https://elevenlabs.io/docs/capabilities/text-to-speech)
*   [Agents Platform Quickstart](https://elevenlabs.io/docs/agents-platform/quickstart)
*   [Sound Effects](https://elevenlabs.io/docs/capabilities/sound-effects)
*   [Forced Alignment (Karaoke)](https://elevenlabs.io/docs/capabilities/forced-alignment)

## ğŸ¤ Contributing

*   **Audio Files:** Stored in `public/hearing-rehab-audio`. Do not rename folders without updating `src/lib/audioUtils.ts`.
*   **New Activities:** Add data to `src/data/` and create a route in `App.tsx`.


